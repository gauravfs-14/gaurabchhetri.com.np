---
name: CrashTransformer - Causal Summarization of Police Crash Narratives
author: Gaurab Chhetri
description: CrashTransformer uses transformer models to convert long police crash narratives into concise, causality-focused summaries that help safety analysts and policymakers act faster. Paper submitted to different venues, will be made available shortly after acceptance.
image: crashtransformer.png
languages: ["Python"]
tags: ["AI", "NLP", "Summarization", "Transportation Safety", "Research"]
type: Research
featured: true
githubUrl: https://github.com/gauravfs-14/CrashTransformer
---

**CrashTransformer** is a research project that turns unstructured police crash narratives into short, causal summaries. Transportation agencies collect thousands of reports each year. The key causes are often buried in long text. CrashTransformer helps surface the root cause, what failed, and why it happened, so teams can move from reading to action.

## Highlights

- **Causality first**: Summaries state the root cause and mechanism, not just a generic recap.  
- **Transformer backbone**: Fine-tuned **BART** for domain-specific abstractive summarization.  
- **Labeling at scale**: Used structured zero-shot and few-shot prompting with **Llama 3.1 8B** to create high-quality reference summaries, which avoids a costly human annotation phase.  
- **Robust evaluation**: Combined **ROUGE** for lexical overlap and **BERTScore** for semantic fidelity, plus cosine similarity and compression analysis.  
- **Practical outputs**: Clear one to two sentence summaries that fit analyst workflows and dashboards.

> Results snapshot: BERTScore F1 â‰ˆ **0.884**, ROUGE-L F1 â‰ˆ **0.327**, mean cosine similarity â‰ˆ **0.647**, compression ratio â‰ˆ **0.743** on a curated benchmark of police narratives.

## Problem and Motivation

Crash narratives are rich with causal signals, but they are hard to search and hard to compare across cities and time. Traditional analysis relies on structured fields and manual coding. That limits depth and scale. We built CrashTransformer to bridge this gap. The goal is to compress long narratives into precise causal statements that analysts and policymakers can use in minutes.

## Method in Brief

- **Data**: 3.9k police crash reports with officer narratives and severity labels following K, A, B, C, O conventions.  
- **Reference summaries**: Generated with carefully designed prompts focused on causal language and error chains.  
- **Model**: **facebook/bart-base** with 110M parameters, trained for short causal outputs.  
- **Evaluation**: ROUGE-1/2/L, **BERTScore**, sentence-embedding cosine similarity, and length compression.

> Why this combo: ROUGE checks surface overlap, BERTScore checks meaning, cosine similarity checks sentence-level alignment, compression checks whether we distill the narrative without losing the cause.

## Example Output

**Input narrative**  
Unit 1 traveled northbound and turned right near a construction zone with cones blocking the right turn lane. Unit 2 had moved safely into the right lane. Unit 1 turned when unsafe and struck Unit 2 in the left front. No injuries reported.

**CrashTransformer summary**  
Unit 1 caused the crash by turning right when it was unsafe, striking Unit 2 that was already in the right lane near the construction zone.

## What the Results Mean

- **High semantic fidelity** suggests the model captures cause and mechanism even when wording differs from references.  
- **Moderate ROUGE** is expected for abstractive models that paraphrase rather than copy text.  
- **Useful compression** reduces reading time while preserving the signal analysts care about.

## Use Cases

- Screen large batches of reports for recurring causal patterns.  
- Feed summaries into severity models and risk dashboards.  
- Support evidence-based interventions for locations, maneuvers, and conditions linked to severe outcomes.

ðŸ‘‰ **Code**: [GitHub Repository](https://github.com/gauravfs-14/CrashTransformer)  
ðŸ“„ **Paper**: manuscript submitted to different venues for review. Will be made available upon acceptance and completed presentation.

## Acknowledgements

Thanks to collaborators at **Texas State University AIT Lab** [^1] for guidance on transportation safety use cases, and to the open source communities behind **Transformers**, **BART**, and **Llama** for the tools that made this project possible.

## References
[^1]: https://ait-lab.vercel.app